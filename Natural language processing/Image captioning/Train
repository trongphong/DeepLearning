{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCH0bF6Toz46RP34x+K4GA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IKKnQcA17Y4s"},"outputs":[],"source":["encoder_att=EncoderAttention().to(device)\n","decoder_att=DecoderAttention().to(device)\n","criterion=nn.CrossEntropyLoss()\n","opt=torch.optim.Adam(decoder_att.parameters())"]},{"cell_type":"code","source":["def training(encoder, decoder, data, n_epochs):\n","    Loss=[]\n","    for epoch in range(n_epochs):\n","        loss_train=0\n","        for i,(img,cap,img_id) in enumerate(data):\n","            encoder_output=encoder(img.to(device))\n","            cap=cap.to(device)\n","            #zero gradient\n","            opt.zero_grad()\n","            #forward\n","            decoder_out=decoder(encoder_output, cap)\n","            loss=criterion(decoder_out.view(-1, decoder_out.size(-1)),\n","                       cap.view(-1).to(torch.int64))#.to(torch.float)\n","            #backward\n","            loss.backward()\n","            #update\n","            opt.step()\n","            loss_train+=loss.item()\n","        Loss.append(loss_train/len(data))\n","        if epoch%10==0:\n","            print(f'Epoch: {epoch}, Loss: {loss_train/len(data)}')\n","    return Loss"],"metadata":{"id":"oJPegkLR7g38"},"execution_count":null,"outputs":[]}]}