{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCHhVVykpSl4r3oFKd6SIU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Encoder model"],"metadata":{"id":"tX7J3Pws6rLf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxRy00_i6gMy"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self):\n","        super(EncoderAttention, self).__init__()\n","        resnet = resnet50(pretrained=True)\n","        self.resnet=nn.Sequential(*list(resnet.children())[:-2])\n","        self.relu = nn.ReLU()\n","    def forward(self, images):\n","        features = self.resnet(images)\n","        features=self.relu(features)\n","        features=features.view(features.size(0), 2048,-1)\n","        features=features.permute(0,2,1)\n","        return features"]},{"cell_type":"markdown","source":["Badraunan Attention"],"metadata":{"id":"tc-Cg3y36zQA"}},{"cell_type":"code","source":["class BahdanauAttention(nn.Module):\n","    def __init__(self, hidden_size=256, attention_dim=64):\n","        super(BahdanauAttention, self).__init__()\n","        self.Ua=nn.Linear(hidden_size, attention_dim)\n","        self.Wa=nn.Linear(hidden_size, attention_dim)\n","        self.Va=nn.Linear(attention_dim,1)\n","    def forward(self, decoder_hidden, encoder_hidden):\n","        sum1=self.Ua(decoder_hidden)\n","        sum2=self.Wa(encoder_hidden)\n","        scores=self.Va(torch.tanh(sum1+sum2))\n","        scores=scores.squeeze(2).unsqueeze(1)\n","        weights=nn.functional.softmax(scores, dim=-1)\n","        context=torch.bmm(weights, encoder_hidden)\n","        return context"],"metadata":{"id":"iCyOFE8_6yzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Decoder RNN with attention"],"metadata":{"id":"1queB4wD7APX"}},{"cell_type":"code","source":["class DecoderAttention(nn.Module):\n","    def __init__(self, vocab_size=vocab_size, feature_size=2048, emb_size=100, hidden_size=256):\n","        super(DecoderAttention, self).__init__()\n","        self.linear1 = nn.Linear(feature_size, hidden_size)\n","        self.embed = nn.Embedding(vocab_size, emb_size)\n","        self.attention=BahdanauAttention()\n","        self.lstm = nn.LSTM(emb_size+hidden_size,hidden_size, batch_first=True)\n","        self.linear2 = nn.Linear(hidden_size, vocab_size)\n","        self.relu=nn.ReLU()\n","        #self.softmax=nn.Softmax()\n","    def forward(self, encoder_outputs, target=None):\n","        encoder_outputs=self.linear1(encoder_outputs)#batch_size, pixed, hidden_size\n","        batch_size=encoder_outputs.size(0)\n","        decoder_input=torch.ones(batch_size, 1, dtype=torch.long)\n","        decoder_hidden=encoder_outputs.mean(dim=1).unsqueeze(dim=0)# 1, batchsize, hidden_size\n","        decoder_cell=encoder_outputs.mean(dim=1).unsqueeze(dim=0)# 1, batch_size, hidden_size\n","        decoder_outputs=[]\n","        for i in range(max_length):\n","            decoder_emb=self.embed(decoder_input.to(device))\n","            decoder_emb=self.relu(decoder_emb) # batch_size,1, emb_size\n","            hidden_att=decoder_hidden.permute(1,0,2)# batch_size, 1, hidden_size\n","            context=self.attention(hidden_att, encoder_outputs) # batch_size, 1, hidden_size\n","            input_lstm=torch.cat((decoder_emb, context), dim=2)\n","            decoder_output, (decoder_hidden, decoder_cell)= self.lstm(input_lstm, (decoder_hidden, decoder_cell))\n","            decoder_output=self.relu(decoder_output)\n","            decoder_output=self.linear2(decoder_output)\n","            decoder_outputs.append(decoder_output)#.squeeze(1))\n","            if target is not None:\n","                decoder_input=target[:,i].unsqueeze(1).to(torch.long)\n","            else:\n","                _, dcd_input=decoder_output.topk(1)\n","                decoder_input=dcd_input.squeeze(-1).detach()\n","        decoder_outputs=torch.cat(decoder_outputs, dim=1)\n","        decoder_output=nn.functional.log_softmax(decoder_output, dim=-1)\n","        return decoder_outputs"],"metadata":{"id":"nEw2pD0k6_3y"},"execution_count":null,"outputs":[]}]}