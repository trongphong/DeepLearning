{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntphong/miniconda3/envs/mlenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point=\"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "#'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "#'microsoft/DialoGPT-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_acc='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' #Llama-meta\n",
    "#token_acc='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' \n",
    "#access_token='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' #Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(check_point,torch_dtype=torch.bfloat16, token=token_acc).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(check_point,token=token_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ntext_gen=model.generate(text_ecd,\\n                        max_length=40,\\n                        #num_beams=5,\\n                        #no_repeat_ngram_size=2,\\n                        do_sample=True,\\n                        top_p=0.9,\\n                        top_k=50,\\n                        #temperature=0.7, \\n                        #attention_mask=token[\\'attention_mask\\'].to(device), \\n                        #early_stopping=True,\\n                        #pad_token_id=tokenizer.eos_token_id\\n                        )\\ntokenizer.decode(text_gen[0], skip_special_tokens=True).split(\"\\n\")           \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "text_gen=model.generate(text_ecd,\n",
    "                        max_length=40,\n",
    "                        #num_beams=5,\n",
    "                        #no_repeat_ngram_size=2,\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                        top_k=50,\n",
    "                        #temperature=0.7, \n",
    "                        #attention_mask=token['attention_mask'].to(device), \n",
    "                        #early_stopping=True,\n",
    "                        #pad_token_id=tokenizer.eos_token_id\n",
    "                        )\n",
    "tokenizer.decode(text_gen[0], skip_special_tokens=True).split(\"\\n\")           \n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nmessages =[\\n    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\\n    {\"role\": \"user\", \"content\": \\'Who are you\\'},\\n]\\ntokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, \\n                                                   add_generation_prompt=True, return_tensors=\"pt\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "messages =[\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": 'Who are you'},\n",
    "]\n",
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, \n",
    "                                                   add_generation_prompt=True, return_tensors=\"pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question):\n",
    "    token=tokenizer(question, return_tensors='pt').to(device) \n",
    "    #both_question=torch.cat([token['input_ids'], torch.LongTensor(history)], dim=-1).to(device)\n",
    "    history=model.generate(**token,\n",
    "                           max_length=100,\n",
    "                           #num_beams=5,\n",
    "                           #no_repeat_ngram_size=2,\n",
    "                           do_sample=True,\n",
    "                           top_p=0.9,\n",
    "                           top_k=50,\n",
    "                           temperature=0.001,\n",
    "                           #attention_mask=token['attention_mask'].to(device), \n",
    "                           #pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    #print(history)\n",
    "    answer=tokenizer.decode(history[0])#.split(\"<|endoftext|>\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>where is Paris, France\\nParis, the capital of France, is located in the country's central region, in the Île-de-France region. It is situated on the Seine River and is the most populous city in France. The city is known for its stunning architecture, art museums, fashion, and romantic atmosphere.\\n\\nHere are some key facts about Paris:\\n\\n* Location: Île-de-France region, central France\\n* Population: approximately 2.1 million\\n* Area\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('where is Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 15 Nov 2024\\n\\nChatBot<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow are you<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm here and ready to help you with any questions or topics you'd like to discuss. How about you? How's your day going?<|eot_id|>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "text='How are you'\n",
    "prompt='ChatBot'\n",
    "test = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "test_token=tokenizer.apply_chat_template( \n",
    "        test,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors='pt').to(device)\n",
    "test_gen=model.generate(\n",
    "        test_token,\n",
    "        max_length=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        temperature=0.0001\n",
    "        )\n",
    "tokenizer.decode(test_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Nov 2024\n",
      "\n",
      "ChatBot<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How are you<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm here and ready to help you with any questions or topics you'd like to discuss. How about you? How's your day going?<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(test_gen[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_chat(text, sys_prompt):\n",
    "    messages =[ \n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    messages_token=tokenizer.apply_chat_template( \n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        #continue_final_message=False,\n",
    "        return_tensors='pt'\n",
    "        ).to(device)\n",
    "    messages_gen=model.generate(\n",
    "        messages_token,\n",
    "        max_length=1000,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        temperature=0.0001,\n",
    "        #pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    ouput=tokenizer.decode(messages_gen[0], skip_special_tokens=True)\n",
    "    return ouput.split('assistant')[-1]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nParis is the capital city of France, a country located in Western Europe. It is situated in the Île-de-France region, which is one of the largest metropolitan areas in Europe.\\n\\nParis is located in the northwestern part of France, approximately 300 kilometers (186 miles) northwest of the English Channel. The city is nestled between the Seine River and the suburbs of Paris, which are home to many of the city's famous landmarks, including the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.\\n\\nHere's a rough outline of Paris's location:\\n\\n* Latitude: 48.8567° N\\n* Longitude: 2.3522° E\\n* Region: Île-de-France\\n* Country: France\\n* Country code: +33\\n* Airport: Charles de Gaulle Airport (CDG)\\n\\nParis is easily accessible by air, with two major airports: Charles de Gaulle Airport (CDG) and Orly Airport (ORY). The city is also connected to other major European cities by high-speed trains, such as the TGV (Train à Grande Vitesse) and the Eurostar.\\n\\nI hope that helps you visualize the location of Paris!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_chat('where is Paris', 'chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntphong/miniconda3/envs/mlenv/lib/python3.10/site-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "demo=gr.ChatInterface(\n",
    "    fn=func_chat,\n",
    "    #type='messages',\n",
    "    textbox=gr.Textbox(placeholder='Enter question here', container=False, scale=7),\n",
    "    chatbot=gr.Chatbot(height=400),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceTB/everyday-conversations-llama3.1-2k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_sft: Dataset({\n",
       "        features: ['topic', 'subtopic', 'subsubtopic', 'full_topic', 'prompt', 'completion', 'token_length', 'messages'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test_sft: Dataset({\n",
       "        features: ['topic', 'subtopic', 'subsubtopic', 'full_topic', 'prompt', 'completion', 'token_length', 'messages'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Shopping',\n",
       " 'subtopic': 'Budgeting',\n",
       " 'subsubtopic': 'Tracking expenses',\n",
       " 'full_topic': 'Shopping/Budgeting/Tracking expenses',\n",
       " 'prompt': 'Generate a very simple multi-turn conversation between a User and an AI Assistant about Shopping/Budgeting/Tracking expenses. The conversation should start with a basic greeting like \"Hello\" or \"Hi\" and be straightforward. Include 3-4 short exchanges. The AI should give brief, clear answers. The User should ask simple questions.\\n\\nStart the conversation like this:\\n\\nUser: [Greeting]\\n\\nAI: Hello! How can I help you today?\\n\\nUser: [Continue with a simple question or statement]\\n\\nAI: [Respond briefly and clearly]\\n\\nUser: [Ask a follow-up question or make another simple statement]\\n\\nAI: [Provide a final helpful response]\\n\\nMake sure the entire conversation remains very simple and easy to understand, focusing on basic topics or requests.',\n",
       " 'completion': \"User: Hi\\n\\nAI: Hello! How can I help you today?\\n\\nUser: I'm trying to track my expenses. Can you help me with that?\\n\\nAI: Yes, I can help you track your expenses. You can start by telling me your income and fixed expenses, such as rent and utilities.\\n\\nUser: That sounds easy. How do I know if I'm staying within my budget?\\n\\nAI: Once you've entered your income and expenses, I can help you set a budget and alert you when you're going over. You can also categorize your spending to see where your money is going.\\n\\nUser: Okay, that sounds great. Can you remind me to review my budget regularly?\\n\\nAI: I can send you reminders to review your budget weekly, monthly, or at any interval you prefer.\",\n",
       " 'token_length': 163,\n",
       " 'messages': [{'content': 'Hey!', 'role': 'user'},\n",
       "  {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       "  {'content': \"I'm trying to track my expenses. Can you help me with that?\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Yes, I can help you track your expenses. You can start by telling me your income and fixed expenses, such as rent and utilities.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': \"That sounds easy. How do I know if I'm staying within my budget?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"Once you've entered your income and expenses, I can help you set a budget and alert you when you're going over. You can also categorize your spending to see where your money is going.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Okay, that sounds great. Can you remind me to review my budget regularly?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'I can send you reminders to review your budget weekly, monthly, or at any interval you prefer.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train_sft'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
